# Mac Installation Guide - Rohstoff Trader

Diese Anleitung hilft Ihnen, die Trading-App auf Ihrem Mac zu installieren und zu betreiben.

## Problem: `emergentintegrations` auf dem Mac

Die App nutzt normalerweise `emergentintegrations` f√ºr LLM-Integration. Diese Bibliothek ist jedoch **nur in der Emergent Cloud verf√ºgbar** und nicht f√ºr lokale Macs.

### ‚úÖ L√∂sung: Automatischer Fallback

Wir haben einen **automatischen Fallback** implementiert, der die Standard-SDKs verwendet:

```
emergentintegrations nicht verf√ºgbar
    ‚Üì
Automatischer Fallback zu:
    ‚Ä¢ OpenAI SDK
    ‚Ä¢ Anthropic SDK  
    ‚Ä¢ Google Generative AI SDK
```

## Installation

### 1. Python-Abh√§ngigkeiten installieren

F√ºr die AI-Features ben√∂tigen Sie die entsprechenden SDKs:

```bash
cd /pfad/zum/trader/backend

# Basis-Installation (ohne AI)
pip install -r requirements.txt

# OPTIONAL: AI-Features aktivieren
# W√§hlen Sie, was Sie brauchen:

# F√ºr OpenAI GPT-4/5
pip install openai

# F√ºr Anthropic Claude
pip install anthropic

# F√ºr Google Gemini
pip install google-generativeai

# Alle AI-Provider
pip install openai anthropic google-generativeai
```

### 2. API-Keys konfigurieren

F√ºgen Sie Ihren API-Key in `backend/.env` hinzu:

```bash
# F√ºr Emergent Universal Key (funktioniert mit allen Providern)
EMERGENT_LLM_KEY=sk-emergent-...

# ODER f√ºr direkten OpenAI Zugriff
OPENAI_API_KEY=sk-...

# ODER f√ºr Claude
ANTHROPIC_API_KEY=sk-ant-...

# ODER f√ºr Gemini
GOOGLE_API_KEY=...
```

### 3. Backend starten

```bash
cd backend
uvicorn server:app --host 0.0.0.0 --port 8001 --reload
```

### 4. Frontend starten

```bash
cd frontend
yarn install
yarn start
```

## AI-Provider Auswahl

In den Einstellungen k√∂nnen Sie w√§hlen:

1. **Emergent LLM Key** (Universal) - Funktioniert mit allen Providern
2. **OpenAI** - Direkter OpenAI Zugriff
3. **Anthropic Claude** - Direkter Claude Zugriff
4. **Google Gemini** - Direkter Gemini Zugriff
5. **Ollama** - Lokal auf Ihrem Mac (100% kostenlos!)

### Empfehlung f√ºr Mac: Ollama

Ollama ist die beste Option f√ºr lokale Entwicklung:

```bash
# Ollama installieren
brew install ollama

# Ollama starten
ollama serve

# Modell herunterladen
ollama pull llama3

# In der App: Provider = "Ollama", Model = "llama3"
```

**Vorteile:**
- ‚úÖ Komplett kostenlos
- ‚úÖ Keine API-Keys n√∂tig
- ‚úÖ L√§uft lokal auf Ihrem Mac
- ‚úÖ Datenschutz (keine Cloud)

## Technische Details

### Wie funktioniert der Fallback?

Die App pr√ºft automatisch, ob `emergentintegrations` verf√ºgbar ist:

```python
# In llm_fallback.py
try:
    from emergentintegrations.llm.chat import LlmChat
    EMERGENT_AVAILABLE = True
except ImportError:
    EMERGENT_AVAILABLE = False
    # Nutze Standard-SDKs
```

### Unterst√ºtzte Provider im Fallback

| Provider | Lokale Installation | Cloud API |
|----------|---------------------|-----------|
| OpenAI | `pip install openai` | ‚úÖ |
| Anthropic | `pip install anthropic` | ‚úÖ |
| Google Gemini | `pip install google-generativeai` | ‚úÖ |
| Ollama | `brew install ollama` | ‚ùå (lokal) |

## Fehlerbehebung

### "emergentintegrations not found"

**Normal!** Das ist kein Fehler. Die App nutzt automatisch den Fallback.

### "OpenAI SDK nicht installiert"

Installieren Sie das ben√∂tigte SDK:
```bash
pip install openai
```

### "API Key ung√ºltig"

Pr√ºfen Sie Ihre API Keys in `backend/.env`:
```bash
cat backend/.env | grep API_KEY
```

## Migration von Emergent Cloud zu Mac

Wenn Sie die App von Emergent Cloud auf Ihren Mac verschieben:

1. ‚úÖ **Code funktioniert ohne √Ñnderungen**
2. ‚úÖ **Automatischer Fallback** zu Standard-SDKs
3. ‚ö†Ô∏è **API-Keys**: M√ºssen in `.env` konfiguriert werden
4. ‚ö†Ô∏è **MetaTrader**: Funktioniert nur √ºber MetaAPI (Cloud)

## Performance-Vergleich

| Provider | Geschwindigkeit | Kosten | Datenschutz |
|----------|----------------|--------|-------------|
| Emergent Cloud | ‚ö°‚ö°‚ö° Sehr schnell | üí∞ Pay-per-use | ‚òÅÔ∏è Cloud |
| OpenAI direkt | ‚ö°‚ö° Schnell | üí∞üí∞ Teurer | ‚òÅÔ∏è Cloud |
| Ollama lokal | ‚ö° Mittel | üÜì Kostenlos | üîí Lokal |

## Zus√§tzliche Ressourcen

- [OpenAI API Docs](https://platform.openai.com/docs)
- [Anthropic Claude Docs](https://docs.anthropic.com)
- [Google Gemini Docs](https://ai.google.dev/docs)
- [Ollama](https://ollama.ai)

## Support

Bei Problemen:
1. Pr√ºfen Sie Backend-Logs: `tail -f /var/log/supervisor/backend.*.log`
2. Pr√ºfen Sie Browser-Konsole (F12)
3. Testen Sie die API: `curl http://localhost:8001/api/market/all`

---

**Wichtig:** Diese App ist f√ºr den pers√∂nlichen Gebrauch bestimmt. Trading birgt Risiken!
